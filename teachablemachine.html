<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Teachable Machine Project</title>
    <link rel="stylesheet" href="stylepage.css">
</head>
<body>
    <header>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="about.html">About Us</a></li>
                <li><a href="resources.html">Resources</a></li>
                <li><a href="techhero.html">Tech Heroes</a></li>
                <li><a href="teachablemachine.html">Teachable Machine</a></li>
            </ul>
        </nav>
    </header>

    <main class="resources">
        <h1>Teachable Machine: Exploring AI and Bias</h1>

        <div class="resource-box">
            <h2>Project Statement</h2>
            <p>
                For this project, I used Google's Teachable Machine to create an image classification model that distinguishes between "Smiling Face" and "Neutral Face." 
                I collected sample images from my laptop webcam, trained the model, and tested it for real-time predictions.
            </p>
            <p>
                While the training process was user-friendly, I encountered issues with lighting inconsistencies and class balance. It showed how even small biases in data (e.g., too many images of one class) impacted the final result.
            </p>
            <p>
                Reflecting on Joy Buolamwini's <em>Unmasking AI</em>, I was reminded how deeply bias can shape systems meant to be "neutral." Like Buolamwini, I noticed how the model responded better to lighter lighting conditions and sometimes misclassified people with darker skin tones. This highlighted the dangers of biased datasets and reminded me that design choices in AI are never neutral.
            </p>
            <p>
                One core lesson I took from the book is that inclusion has to be intentional—not an afterthought. Training a model isn't just about technical accuracy—it's about ethical responsibility. I now better understand why Buolamwini calls for audits, transparency, and community input in AI development.
            </p>
            <p>
                In the future, I want to explore more inclusive training practices and experiment with larger, more diverse datasets. This experience emphasized that technology reflects the values we embed in it—and we must constantly work to unlearn bias as we build.
            </p>
            <p><strong>Group Members:</strong> Zuheb Ibrahim, Ulises Sanchez</p>
        </div>

        <div class="resource-box">
            <h2>Video: Teachable Machine in Action</h2>
            <p>Watch our classifier working in real-time:</p>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/your-video-id-here" frameborder="0" allowfullscreen></iframe>
        </div>

        <div class="resource-box">
            <h2>Download the Model</h2>
            <p>Click the link below to download the exported Teachable Machine model:</p>
            <a href="downloads/TeachableModel.zip" target="_blank">Download Model Files (.zip)</a>
        </div>

        <div class="resource-box">
            <h2>GitHub Repository</h2>
            <p>You can view our full project files and documentation on GitHub:</p>
            <a href="https://teachablemachine.withgoogle.com/models/ybXBzoWbR/" target="_blank">GitHub Repository</a>
        </div>
    </main>

    <footer>
        <p>&copy; 2025 Code & Power Project</p>
    </footer>
</body>
</html>
